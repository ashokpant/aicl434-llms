{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555117cf11a59d8e",
   "metadata": {},
   "source": [
    "#  TF-IDF\n",
    "Ashok Kumar Pant | AI Solution Architect | CTO and Co-founder at Treeleaf/Anydone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac3b8138e624c1",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization\n",
    "\n",
    "Term frequency (TF): Term frequency is simply the ratio of the count of a\n",
    "word present in a sentence, to the length of the sentence.\n",
    "\n",
    "TF is basically capturing the importance of the word irrespective of the\n",
    "length of the document. For example, a word with the frequency of 3 with\n",
    "the length of sentence being 10 is not the same as when the word length of\n",
    "sentence is 100 words. It should get more importance in the first scenario;\n",
    "that is what TF does.\n",
    "\n",
    "Inverse Document Frequency (IDF): IDF of each word is the log of\n",
    "the ratio of the total number of rows to the number of rows in a particular\n",
    "document in which that word is present.\n",
    "\n",
    "IDF = log(N/n), where N is the total number of rows and n is the\n",
    "number of rows in which the word was present.\n",
    "\n",
    "IDF will measure the rareness of a term. Words like “a,” and “the” show\n",
    "up in all the documents of the corpus, but rare words will not be there\n",
    "in all the documents. So, if a word is appearing in almost all documents,\n",
    "then that word is of no use to us since it is not helping to classify or in\n",
    "information retrieval. IDF will nullify this problem.\n",
    "\n",
    "TF-IDF is the simple product of TF and IDF so that both of the\n",
    "drawbacks are addressed, which makes predictions and information\n",
    "retrieval relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872a1b4762376d34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T05:32:18.032920Z",
     "start_time": "2025-03-19T05:32:18.030744Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07213df831f93fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T05:32:21.822425Z",
     "start_time": "2025-03-19T05:32:21.818299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
      "IDF Values:\n",
      "[1.69314718 1.28768207 1.28768207 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.        ]\n",
      "TF-IDF Matrix:\n",
      "[[0.36388646 0.27674503 0.27674503 0.36388646 0.36388646 0.36388646\n",
      "  0.36388646 0.42983441]\n",
      " [0.         0.78980693 0.         0.         0.         0.\n",
      "  0.         0.61335554]\n",
      " [0.         0.         0.78980693 0.         0.         0.\n",
      "  0.         0.61335554]]\n",
      "Feature Names:\n",
      "['brown' 'dog' 'fox' 'jumped' 'lazy' 'over' 'quick' 'the']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Step 1: Prepare the text data\n",
    "text = [\n",
    "    \"The quick brown fox jumped over the lazy dog.\",\n",
    "    \"The dog.\",\n",
    "    \"The fox\"\n",
    "]\n",
    "\n",
    "# Step 2: Create TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 3: Fit the vectorizer to the text (build vocabulary)\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# Step 4: Print vocabulary\n",
    "print(\"Vocabulary:\")\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "# Step 5: Print IDF values\n",
    "print(\"IDF Values:\")\n",
    "print(vectorizer.idf_)\n",
    "\n",
    "# Step 6: Transform the text to TF-IDF features\n",
    "tfidf_matrix = vectorizer.transform(text)\n",
    "\n",
    "# Step 7: Print the TF-IDF matrix\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())\n",
    "\n",
    "# Step 8: Get feature names to understand the matrix\n",
    "print(\"Feature Names:\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# Vocabulary:\n",
    "# {'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
    "# IDF Values:\n",
    "# [1.69314718 1.28768207 1.28768207 1.69314718 1.69314718 1.69314718 1.69314718 1.        ]\n",
    "# TF-IDF Matrix:\n",
    "# [[0.36388646 0.27674503 0.27674503 0.36388646 0.36388646 0.36388646 0.36388646 0.42983441]\n",
    "#  [0.         0.78980693 0.         0.         0.         0.         0.         0.61335554]\n",
    "#  [0.         0.         0.78980693 0.         0.         0.         0.         0.61335554]]\n",
    "# Feature Names:\n",
    "# ['brown' 'dog' 'fox' 'jumped' 'lazy' 'over' 'quick' 'the']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baee8b0-290b-4c08-8091-e7af3075a0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
