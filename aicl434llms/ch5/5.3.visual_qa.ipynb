{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # Visual Question Answering with BLIP-2\n",
    " Ashok Kumar Pant"
   ],
   "id": "5c246191db574574"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model setup",
   "id": "3406c2f7bf47a067"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T08:09:18.068392Z",
     "start_time": "2025-06-19T08:08:58.506235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "blip_processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "model = model.to(device)"
   ],
   "id": "2a550305680648d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ba27e9a2d7f4de69879a8907e3fa9e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors: 100%|#########9| 9.92G/9.96G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e661c347e5f6447d9192561ea62189f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a23b00e844104663b1b0cbf8502a5f7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34010df2e3d84f568cf16e8454afcddc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and preprocess an image",
   "id": "cf63c4d0b40c2cea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T08:11:42.373676Z",
     "start_time": "2025-06-19T08:11:42.300623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# image_path = \"https://www.detailingdevils.com/uploads/blogs/Lamborghini-Revuelto.webp\"\n",
    "# image = Image.open(urlopen(image_path)).convert(\"RGB\")\n",
    "\n",
    "image_path = \"/Users/ashokpant/Projects/treeleaf/smartid-processor/data/np_nationalid_data/Driver Licence/1DL.png\"\n",
    "image = Image.open(image_path).convert(\"RGB\")"
   ],
   "id": "ff61115838e8441e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visual Question Answering (VQA)",
   "id": "3c0b8781938d72c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T08:12:45.997204Z",
     "start_time": "2025-06-19T08:12:43.995842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Question: Write down what you see in this picture. Answer:\"\n",
    "inputs = blip_processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=30)\n",
    "generated_text = blip_processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "print(generated_text)"
   ],
   "id": "af6192b14987aeca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chat-like follow-up prompting",
   "id": "45a6b5e111ebde64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T08:13:17.108295Z",
     "start_time": "2025-06-19T08:13:12.374579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = (\n",
    "    \"Question: Write down what you see in this picture. Answer: A sports car driving on the road at sunset. \"\n",
    "    \"Question: What would it cost me to drive that car? Answer:\"\n",
    ")\n",
    "inputs = blip_processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=30)\n",
    "generated_text = blip_processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "print(generated_text)\n"
   ],
   "id": "820f847f4212baf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it would cost me a lot of money\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Interactive Chatbot using gradio (for Jupyter notebooks)\n",
   "id": "58c17574642ee7d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T08:13:42.598925Z",
     "start_time": "2025-06-19T08:13:40.835928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "\n",
    "memory = []\n",
    "\n",
    "\n",
    "def qa_with_memory(user_input):\n",
    "    if user_input.strip() == \"\":\n",
    "        return \"\", \"\"\n",
    "\n",
    "    # Create the prompt from memory\n",
    "    prompt = \" \".join(\n",
    "        [f\"Question: {q} Answer: {a}.\" for q, a in memory]\n",
    "    ) + f\" Question: {user_input} Answer:\"\n",
    "\n",
    "    # Process inputs\n",
    "    inputs = blip_processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=100)\n",
    "    answer = blip_processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip().split(\"Question\")[\n",
    "        0].strip()\n",
    "\n",
    "    # Store to memory\n",
    "    memory.append((user_input, answer))\n",
    "\n",
    "    # Build output history\n",
    "    history_html = \"\"\n",
    "    for q, a in memory:\n",
    "        history_html += f\"<b>USER:</b> {q}<br><b>BLIP-2:</b> {a}<br><br>\"\n",
    "\n",
    "    return history_html, \"\"\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.HTML()\n",
    "    user_input = gr.Textbox(placeholder=\"Ask something about the image...\")\n",
    "\n",
    "    user_input.submit(qa_with_memory, inputs=user_input, outputs=[chatbot, user_input])\n",
    "\n",
    "demo.launch()"
   ],
   "id": "186127fb22e75e33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
