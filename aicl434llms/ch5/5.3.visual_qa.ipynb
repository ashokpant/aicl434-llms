{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # Visual Question Answering with BLIP-2\n",
    " Ashok Kumar Pant"
   ],
   "id": "5c246191db574574"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model setup",
   "id": "3406c2f7bf47a067"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-12T04:04:49.299405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "blip_processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "model = model.to(device)"
   ],
   "id": "2a550305680648d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/432 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fe6740a780b4dc8a7c4c8f9ce8faa8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/21.0k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c5d351ae6834737bc519ecd61f2e253"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41bd1b6ea0a74004a0f0eb13456bfd03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1f06da8bc884d12b9de0afc7a1bcf1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49d6f2d3ceff4f7481cf337a8c520278"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97517217f2564f8698d08397880cc3cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e8725d5637048a8a71a2ab79c0352d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/2.22k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18365a618161427e8f99db65f2d95ff5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/128k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abb34580e5ce4d878029bf9b3ebb6814"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79f6acb286ee45f0bf69495130a67e12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/5.81G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfeaafac45e44a6f981f76b47d6e2e0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df709dc149f24fd2983ff92c60b91dd0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/0a/95/0a959ad2bb676ad75f985d587afb299b8844a9fb270bcdabd46eb95042b394e7/c77bd5bcdbc0945c57444d34d28bd4452dc715c3d8aef54e2e91459fdafb7e03?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&Expires=1749704705&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTcwNDcwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8wYS85NS8wYTk1OWFkMmJiNjc2YWQ3NWY5ODVkNTg3YWZiMjk5Yjg4NDRhOWZiMjcwYmNkYWJkNDZlYjk1MDQyYjM5NGU3L2M3N2JkNWJjZGJjMDk0NWM1NzQ0NGQzNGQyOGJkNDQ1MmRjNzE1YzNkOGFlZjU0ZTJlOTE0NTlmZGFmYjdlMDM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=UF2uq41IFsG1u-9ayw9Q5E8L1YlSnEpUIwG-F6LW0KEaCN2rDPP-YrJaFslGIpEPfhx%7EwQr2Nh6iW40u7-Zvv46ZlANXD6HcroDliXTS5a5ueTtSI1lajt5E4QzgPtI0MjIMx9iSiJFcbr16ntT-yNJqf-k0cXADqDKomq9ou0-8-NU9FUd91EdQmKoHOidgVusihJz3OOssiQfiC-H1DfE-PRkdh025whtiSSv1yHgkY78ZEJ8FkN%7EZtmlkQLRII4jskDHHtwStlpUR22GOp1LdDYCqcR5Iqy5gGdGpMqF%7EbPyLL6hnoI-FcfecNHp7OUdutSpLxSCf7tLJx5qyBQ__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/repos/0a/95/0a959ad2bb676ad75f985d587afb299b8844a9fb270bcdabd46eb95042b394e7/23bb7a7a78644afa9a138dd6c4360edf51ca5fc6da1c5d01f147b964ad7c0c6d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1749704705&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTcwNDcwNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8wYS85NS8wYTk1OWFkMmJiNjc2YWQ3NWY5ODVkNTg3YWZiMjk5Yjg4NDRhOWZiMjcwYmNkYWJkNDZlYjk1MDQyYjM5NGU3LzIzYmI3YTdhNzg2NDRhZmE5YTEzOGRkNmM0MzYwZWRmNTFjYTVmYzZkYTFjNWQwMWYxNDdiOTY0YWQ3YzBjNmQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=rFd1NwBEpn4srWew1qYVb1e-vIF46-1D5TJZS9R2WlGXHQ%7EIMZlsPvMExYuTD1gnipWJyWL%7EWmeyNszQxwshVMvWO33AiVW-toJubHAdO3xrLQRHBMOVHtKx8G6waq2B6ylu1ezZu9mEKPxs1efylMogii%7E14QMArUrUV1JK4uZ1VTjwdSrYwC92eUROVm4kL3PYeJXEI1btAXOsnlqGr25Ukox5Fh1dikj4Obog%7ENiclm1S-TzZv3MCfoiPqeDb5GNc9pCUN3GT-IN1vOIOo40QN09n-yPIgcpuleYu2BK7%7E-K6G9ZGmgTA%7E67ra6pWMN0qAr%7EYySH3nL3Rnwmnew__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:  28%|##7       | 2.77G/9.96G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e0531109ff54fb9bae490f2ff80ce37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:  51%|#####     | 2.94G/5.81G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2c655c3f82a4768b30e9ecd60ae251b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and preprocess an image",
   "id": "cf63c4d0b40c2cea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "car_path = \"https://www.detailingdevils.com/uploads/blogs/Lamborghini-Revuelto.webp\"  # Replace with actual URL or local path\n",
    "image = Image.open(urlopen(car_path)).convert(\"RGB\")"
   ],
   "id": "ff61115838e8441e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visual Question Answering (VQA)",
   "id": "3c0b8781938d72c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"Question: Write down what you see in this picture. Answer:\"\n",
    "inputs = blip_processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=30)\n",
    "generated_text = blip_processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "print(generated_text)"
   ],
   "id": "af6192b14987aeca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chat-like follow-up prompting",
   "id": "45a6b5e111ebde64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = (\n",
    "    \"Question: Write down what you see in this picture. Answer: A sports car driving on the road at sunset. \"\n",
    "    \"Question: What would it cost me to drive that car? Answer:\"\n",
    ")\n",
    "inputs = blip_processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=30)\n",
    "generated_text = blip_processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "print(generated_text)\n"
   ],
   "id": "820f847f4212baf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Interactive Chatbot using gradio (for Jupyter notebooks)\n",
   "id": "58c17574642ee7d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T03:27:45.948650Z",
     "start_time": "2025-06-12T03:27:42.462797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "\n",
    "memory = []\n",
    "\n",
    "\n",
    "def qa_with_memory(user_input):\n",
    "    if user_input.strip() == \"\":\n",
    "        return \"\", \"\"\n",
    "\n",
    "    # Create the prompt from memory\n",
    "    prompt = \" \".join(\n",
    "        [f\"Question: {q} Answer: {a}.\" for q, a in memory]\n",
    "    ) + f\" Question: {user_input} Answer:\"\n",
    "\n",
    "    # Process inputs\n",
    "    inputs = blip_processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=100)\n",
    "    answer = blip_processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip().split(\"Question\")[\n",
    "        0].strip()\n",
    "\n",
    "    # Store to memory\n",
    "    memory.append((user_input, answer))\n",
    "\n",
    "    # Build output history\n",
    "    history_html = \"\"\n",
    "    for q, a in memory:\n",
    "        history_html += f\"<b>USER:</b> {q}<br><b>BLIP-2:</b> {a}<br><br>\"\n",
    "\n",
    "    return history_html, \"\"\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.HTML()\n",
    "    user_input = gr.Textbox(placeholder=\"Ask something about the image...\")\n",
    "\n",
    "    user_input.submit(qa_with_memory, inputs=user_input, outputs=[chatbot, user_input])\n",
    "\n",
    "demo.launch()"
   ],
   "id": "186127fb22e75e33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ashokpant/miniconda3/envs/ml/lib/python3.12/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ashokpant/miniconda3/envs/ml/lib/python3.12/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ashokpant/miniconda3/envs/ml/lib/python3.12/site-packages/gradio/blocks.py\", line 2218, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ashokpant/miniconda3/envs/ml/lib/python3.12/site-packages/gradio/blocks.py\", line 1729, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ashokpant/miniconda3/envs/ml/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ashokpant/miniconda3/envs/ml/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/ashokpant/miniconda3/envs/ml/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ashokpant/miniconda3/envs/ml/lib/python3.12/site-packages/gradio/utils.py\", line 894, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/5_/jdfvrxgj605gsqb_0h_dw6kr0000gn/T/ipykernel_12171/3111499975.py\", line 16, in qa_with_memory\n",
      "    inputs = blip_processor(image, text=prompt, return_tensors=\"pt\").to(device, torch.float16)\n",
      "             ^^^^^^^^^^^^^^\n",
      "NameError: name 'blip_processor' is not defined\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
